
R version 3.3.0 Patched (2016-05-26 r70671) -- "Supposedly Educational"
Copyright (C) 2016 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> ## test handing of NA coefficients / singular fits
> ## also check:
> ## -- what would have to be done if class "lm" was added.
> ## -- general compatibility to class lm.
> require(robustbase)
Loading required package: robustbase
> source(system.file("test-tools-1.R", package="Matrix", mustWork=TRUE))
Loading required package: tools
> ##-> assertError(), etc
> 
> ## generate simple example data
> data <- expand.grid(x1=letters[1:3], x2=LETTERS[1:3], rep=1:3)
> set.seed(1)
> data$y <- rnorm(nrow(data))
> ## drop all combinations of one interaction:
> data <- subset(data, x1 != 'c' | (x2 != 'B' & x2 != 'C'))
> ## add collinear variables
> data$x3 <- rnorm(nrow(data))
> data$x4 <- rnorm(nrow(data))
> data$x5 <- data$x3 + data$x4
> ## add some NA terms
> data$y[1] <- NA
> data$x4[2:3] <- NA ## to test anova
> 
> ## Classical models start with 'cm', robust just with  'rm' (or just 'm'):
> cm0 <- lm   (y ~ x1*x2 + x3,	       data)
> cm1 <- lm   (y ~ x1*x2 + x3 + x4 + x5, data)
> set.seed(2)
> rm1 <- lmrob(y ~ x1*x2 + x3 + x4 + x5, data)
> m3  <- lmrob(y ~ x1*x2 + x3 + x4,      data) # same column space as rm1
> rm0 <- lmrob(y ~ x1*x2 + x3,	       data)
> 
> ## clean version of rm1 (to check predict)
> data2 <- data.frame(y=data$y[-(1:3)], rm1$x[,!is.na(rm1$coef)])
> set.seed(2)
> rm1c <- lmrob(y ~ x1b + x1c + x2B + x2C + x3 + x4 + x1b:x2B + x1b:x2C, data2)
> 
> ## add class lm to rm1 (for now)
> class(rm1) <- c(class(rm1), "lm")
> class(rm0) <- c(class(rm0), "lm")
> 
> ## the full matrix (data) should be returned by model matrix (frame)
> stopifnot(all.equal(model.matrix(cm1), model.matrix(rm1)),
+           all.equal(model.frame (cm1), model.frame (rm1)))
> ## qr decomposition should be for the full data and pivots identical lm result
> qr.cm1 <- qr(cm1)$qr
> qr.rm1 <- rm1$qr$qr
> stopifnot(NCOL(qr.rm1) == NCOL(qr.cm1),
+           NROW(qr.rm1) == NROW(qr.cm1),
+           length(rm1$qr$qraux) == length(qr(cm1)$qraux),
+           all.equal(rm1$qr$pivot, qr(cm1)$pivot),
+           all.equal(dimnames(qr.rm1),dimnames(qr.cm1)))
> ## the alias function should return the same result
> stopifnot(all.equal(alias(cm1), alias(rm1)))
> 
> ####
> ## these helper functions should print NAs for the dropped coefficients
>   print(rm1)

Call:
lmrob(formula = y ~ x1 * x2 + x3 + x4 + x5, data = data)
 \--> method = "MM"
Coefficients:
(Intercept)          x1b          x1c          x2B          x2C           x3  
    0.43807      0.59683      0.03444      0.20121      0.17886     -0.13200  
         x4           x5      x1b:x2B      x1c:x2B      x1b:x2C      x1c:x2C  
   -0.21554           NA     -1.87628           NA     -0.86505           NA  

> summary(rm1) -> s1
> confint(rm1) -> ci1
> stopifnot(identical(is.na(coef(cm1)), apply(ci1, 1L, anyNA)),
+ 	  identical(sigma(rm1), s1$ sigma),
+ 	  identical(vcov(rm1),  s1$ cov  ),
+ 	  TRUE)
> 
> print(s1, showAlgo=FALSE)

Call:
lmrob(formula = y ~ x1 * x2 + x3 + x4 + x5, data = data)
 \--> method = "MM"
Residuals:
     Min       1Q   Median       3Q      Max 
-1.45843 -0.35555  0.02458  0.36512  1.02964 

Coefficients: (3 not defined because of singularities)
            Estimate Std. Error t value Pr(>|t|)
(Intercept)  0.43807    0.54435   0.805    0.442
x1b          0.59683    0.64226   0.929    0.377
x1c          0.03444    0.68798   0.050    0.961
x2B          0.20121    0.71643   0.281    0.785
x2C          0.17886    0.68711   0.260    0.800
x3          -0.13200    0.41546  -0.318    0.758
x4          -0.21554    0.16935  -1.273    0.235
x5                NA         NA      NA       NA
x1b:x2B     -1.87628    1.21526  -1.544    0.157
x1c:x2B           NA         NA      NA       NA
x1b:x2C     -0.86505    0.74657  -1.159    0.276
x1c:x2C           NA         NA      NA       NA

Robust residual standard error: 0.9273 
Multiple R-squared:  0.3377,	Adjusted R-squared:  -0.251 
Convergence in 15 IRWLS iterations

Robustness weights: 
 2 weights are ~= 1. The remaining 16 ones are summarized as
   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.7873  0.9365  0.9847  0.9519  0.9876  0.9943 
> ci1
                 2.5 %    97.5 %
(Intercept) -0.7933283 1.6694600
x1b         -0.8560712 2.0497272
x1c         -1.5218838 1.5907552
x2B         -1.4194772 1.8218924
x2C         -1.3754930 1.7332032
x3          -1.0718248 0.8078296
x4          -0.5986340 0.1675623
x5                  NA        NA
x1b:x2B     -4.6253943 0.8728291
x1c:x2B             NA        NA
x1b:x2C     -2.5539127 0.8238074
x1c:x2C             NA        NA
> ## drop1 should return df = 0
> #drop1(rm1) ## drop.lm does not return valid results (yet)!
> 
> ####
> ## methods that should just drop the NA coefficients
> ## m3 is actually the same as rm1, so anova should raise an error
> assertError(anova(rm1, m3, test="Wald"))
> assertError(anova(rm1, m3, test="Deviance"))
> ## but comparing rm1 and rm0 should be ok
> anova(rm1, rm0, test="Wald")
Robust Wald Test Table

Model 1: y ~ x1 * x2 + x3 + x4 + x5
Model 2: y ~ x1 * x2 + x3
Largest model fitted by lmrob(), i.e. SM

  pseudoDf Test.Stat Df Pr(>chisq)
1        6                        
2       10    1.6198  1     0.2031
> anova(rm1, rm0, test="Deviance")
Robust Deviance Table

Model 1: y ~ x1 * x2 + x3 + x4 + x5
Model 2: y ~ x1 * x2 + x3
Largest model fitted by lmrob(), i.e. SM

  pseudoDf Test.Stat Df Pr(>chisq)
1        6                        
2       10    1.3955  1     0.2375
> ## commands with single #:
> ## they do (or might) not return sensible results for robust fits
> ## and need to be checked again
> #cooks.distance(rm1)
> #deviance(rm1)
> #dfbeta(rm1)
> #dfbetas(rm1)
> #effects(rm1) ## fails
> #extractAIC(rm1)
> #influence(rm1)
> stopifnot(all.equal(hv1 <- hatvalues(rm1), .lmrob.hat(wqr=rm1$qr), tol=1e-15),
+           all.equal(hv1, stats:::hatvalues.lm(rm1), tol=1e-15),
+           all.equal(hat(cm1$qr), unname(hatvalues(cm1)), tol=1e-15),
+           all.equal(unname(hv1), hat(rm1$qr), tol=1e-15),
+           ## ditto :
+           all.equal(hv1c <- hatvalues(rm1c), stats:::hatvalues.lm(rm1c), tol=1e-15))
> 
> ## kappa() & labels() :
> stopifnot(is.infinite(kr1 <- kappa(rm1)), kr1 == kappa(cm1), # = +Inf both
+           identical(labels(rm1), labels(cm1)))
> logLik(rm1)# well, and what does it mean?
'log Lik.' -17.67002 (df=10)
> ## plot(rm1, which=1) ## plot.lmrob() fails "singular covariance" .. FIXME!
> par(mfrow=c(2,2))
> plot(rm1, which=2:4)
> stopifnot(all.equal(predict(rm1), predict(rm1c), tol=1e-15),
+           all.equal(predict(rm1,  se.fit=TRUE, interval="confidence"),
+ 		    predict(rm1c, se.fit=TRUE, interval="confidence"), tol=1e-15))
> predict(rm1, type="terms", se.fit=TRUE, interval="confidence")
$fit
           x1          x2          x3            x4 x5      x1:x2
4  -0.2690831  0.07452003 -0.16629001  0.1723379507  0  0.4568892
5   0.3277449  0.07452003  0.02662015 -0.0330991609  0 -1.4193934
7  -0.2690831  0.05216753 -0.03811930  0.2838425350  0  0.4568892
8   0.3277449  0.05216753  0.02015455 -0.2684435741  0 -0.4081634
10 -0.2690831 -0.12668756  0.19482096 -0.3864227450  0  0.4568892
11  0.3277449 -0.12668756  0.06783070  0.1195737252  0  0.4568892
12 -0.2346474 -0.12668756  0.06509774  0.2654727479  0  0.4568892
13 -0.2690831  0.07452003  0.02088164 -0.0823706328  0  0.4568892
14  0.3277449  0.07452003 -0.13214829  0.0695334507  0 -1.4193934
16 -0.2690831  0.05216753 -0.08768495 -0.4772102773  0  0.4568892
17  0.3277449  0.05216753  0.03476913  0.0488819732  0 -0.4081634
19 -0.2690831 -0.12668756  0.04649555 -0.1082391834  0  0.4568892
20  0.3277449 -0.12668756 -0.07894507  0.0343888795  0  0.4568892
21 -0.2346474 -0.12668756 -0.06042579  0.2006263392  0  0.4568892
22 -0.2690831  0.07452003  0.10396651 -0.0002671534  0  0.4568892
23  0.3277449  0.07452003  0.10644007  0.4294575642  0 -1.4193934
25 -0.2690831  0.05216753 -0.03507153 -0.2754552040  0  0.4568892
26  0.3277449  0.05216753 -0.08839208  0.0073927654  0 -0.4081634
attr(,"constant")
[1] 0.3234705

$se.fit
          x1        x2         x3           x4 x5     x1:x2
4  0.3519162 0.4201046 0.52338997 0.1354093877  0 0.2901316
5  0.2958190 0.4201046 0.08378566 0.0260066752  0 0.9501207
7  0.3519162 0.4034458 0.11997871 0.2230207782  0 0.2901316
8  0.2958190 0.4034458 0.06343550 0.2109215055  0 0.5382701
10 0.3519162 0.4019138 0.61318978 0.3036201086  0 0.2901316
11 0.2958190 0.4019138 0.21349392 0.0939514764  0 0.2901316
12 0.4041062 0.4019138 0.20489207 0.2085872677  0 0.2901316
13 0.3519162 0.4201046 0.06572398 0.0647202599  0 0.2901316
14 0.2958190 0.4201046 0.41593049 0.0546338281  0 0.9501207
16 0.3519162 0.4034458 0.27598423 0.3749536954  0 0.2901316
17 0.2958190 0.4034458 0.10943421 0.0384075477  0 0.5382701
19 0.3519162 0.4019138 0.14634254 0.0850456994  0 0.2901316
20 0.2958190 0.4019138 0.24847589 0.0270200331  0 0.2901316
21 0.4041062 0.4019138 0.19018731 0.1576361425  0 0.2901316
22 0.3519162 0.4201046 0.32722968 0.0002099078  0 0.2901316
23 0.2958190 0.4201046 0.33501511 0.3374334300  0 0.9501207
25 0.3519162 0.4034458 0.11038597 0.2164306838  0 0.2901316
26 0.2958190 0.4034458 0.27820990 0.0058086442  0 0.5382701

$lwr
           x1         x2         x3            x4 x5     x1:x2
4  -1.0651728 -0.8758227 -1.3502804 -0.1339793657  0 -0.199434
5  -0.3414441 -0.8758227 -0.1629162 -0.0919303475  0 -3.568716
7  -1.0651728 -0.8604902 -0.3095300 -0.2206655158  0 -0.199434
8  -0.3414441 -0.8604902 -0.1233465 -0.7455811685  0 -1.625815
10 -1.0651728 -1.0358798 -1.1923107 -1.0732591485  0 -0.199434
11 -0.3414441 -1.0358798 -0.4151261 -0.0929592802  0 -0.199434
12 -1.1487992 -1.0358798 -0.3984003 -0.2063844337  0 -0.199434
13 -1.0651728 -0.8758227 -0.1277963 -0.2287780323  0 -0.199434
14 -0.3414441 -0.8758227 -1.0730484 -0.0540568550  0 -3.568716
16 -1.0651728 -0.8604902 -0.7120046 -1.3254144650  0 -0.199434
17 -0.3414441 -0.8604902 -0.2127882 -0.0380019359  0 -1.625815
19 -1.0651728 -1.0358798 -0.2845543 -0.3006259215  0 -0.199434
20 -0.3414441 -1.0358798 -0.6410366 -0.0267346818  0 -0.199434
21 -1.1487992 -1.0358798 -0.4906594 -0.1559713896  0 -0.199434
22 -1.0651728 -0.8758227 -0.6362785 -0.0007419977  0 -0.199434
23 -0.3414441 -0.8758227 -0.6514167 -0.3338698864  0 -3.568716
25 -1.0651728 -0.8604902 -0.2847819 -0.7650554255  0 -0.199434
26 -0.3414441 -0.8604902 -0.7177466 -0.0057473006  0 -1.625815
attr(,"constant")
[1] 0.3234705

$upr
          x1        x2        x3          x4 x5     x1:x2
4  0.5270067 1.0248627 1.0177003 0.478655267  0 1.1132125
5  0.9969340 1.0248627 0.2161565 0.025732026  0 0.7299289
7  0.5270067 0.9648253 0.2332914 0.788350586  0 1.1132125
8  0.9969340 0.9648253 0.1636556 0.208694020  0 0.8094881
10 0.5270067 0.7825046 1.5819526 0.300413658  0 1.1132125
11 0.9969340 0.7825046 0.5507875 0.332106730  0 1.1132125
12 0.6795044 0.7825046 0.5285958 0.737329930  0 1.1132125
13 0.5270067 1.0248627 0.1695596 0.064036767  0 1.1132125
14 0.9969340 1.0248627 0.8087518 0.193123756  0 0.7299289
16 0.5270067 0.9648253 0.5366347 0.370993910  0 1.1132125
17 0.9969340 0.9648253 0.2823265 0.135765882  0 0.8094881
19 0.5270067 0.7825046 0.3775454 0.084147555  0 1.1132125
20 0.9969340 0.7825046 0.4831464 0.095512441  0 1.1132125
21 0.6795044 0.7825046 0.3698078 0.557224068  0 1.1132125
22 0.5270067 1.0248627 0.8442115 0.000207691  0 1.1132125
23 0.9969340 1.0248627 0.8642969 1.192785015  0 0.7299289
25 0.5270067 0.9648253 0.2146389 0.214145018  0 1.1132125
26 0.9969340 0.9648253 0.5409624 0.020532831  0 0.8094881
attr(,"constant")
[1] 0.3234705

$df
[1] 9

$residual.scale
[1] 0.9272562

> #proj(rm1) ## fails "FIXME"
> residuals(rm1)
          4           5           7           8          10          11 
 1.00343616  1.02964466 -0.32173838  0.69139416 -0.49837572  0.34295962 
         12          13          14          16          17          19 
-0.35975204 -1.14554829 -1.45842718 -0.04348259 -0.39506094  0.49837572 
         20          21          22          23          25          26 
-0.34295962  0.35975204  0.09264024  0.23232522  0.36690827 -0.27034899 
> #rstandard(rm1)
> #rstudent(rm1)
> #simulate(rm1) ## just $weights needs to be changed to prior weights
> V1 <- vcov(rm1) # but don't show the "eigen" part {vectors may flip sign}:
> attributes(V1) <- attributes(V1)[c("dim","dimnames", "weights")]; V1
            (Intercept)         x1b         x1c         x2B          x2C
(Intercept)   0.2963116 -0.32142943 -0.33884229 -0.23800957 -0.328912503
x1b          -0.3214294  0.41250140  0.36976330  0.25303831  0.361676665
x1c          -0.3388423  0.36976330  0.47331685  0.27481116  0.349759210
x2B          -0.2380096  0.25303831  0.27481116  0.51327672  0.234208590
x2C          -0.3289125  0.36167666  0.34975921  0.23420859  0.472118513
x3            0.1357438 -0.15944754 -0.14643355 -0.06405995 -0.229404383
x4           -0.0352579  0.03959798  0.06058715  0.03535934  0.002486439
x1b:x2B       0.3051623 -0.39975373 -0.27325972 -0.55783994 -0.521953886
x1b:x2C       0.3214233 -0.41415875 -0.34909218 -0.23309712 -0.439407806
                      x3           x4     x1b:x2B     x1b:x2C
(Intercept)  0.135743809 -0.035257897  0.30516225  0.32142326
x1b         -0.159447536  0.039597977 -0.39975373 -0.41415875
x1c         -0.146433546  0.060587148 -0.27325972 -0.34909218
x2B         -0.064059946  0.035359338 -0.55783994 -0.23309712
x2C         -0.229404383  0.002486439 -0.52195389 -0.43940781
x3           0.172603846  0.003718667  0.30873497  0.20392531
x4           0.003718667  0.028679697  0.06374335 -0.01243466
x1b:x2B      0.308734967  0.063743354  1.47685967  0.49806038
x1b:x2C      0.203925311 -0.012434662  0.49806038  0.55736770
attr(,"weights")
        4         5         7         8        10        11        12        13 
0.8961427 0.8908052 0.9890601 0.9499832 0.9738515 0.9875740 0.9863317 0.8657671 
       14        16        17        19        20        21        22        23 
0.7872941 0.9997996 0.9835287 0.9738515 0.9875740 0.9863317 0.9990907 0.9942882 
       25        26 
0.9857845 0.9922695 
> set.seed(12); sc <- simulate(cm1, 64)
> set.seed(12); rc <- simulate(rm1, 64)
> 
> stopifnot(all.equal(sqrt(diag(V1)), coef(summary(rm1))[,"Std. Error"], tol=1e-15),
+ 	  all.equal(sc, rc, tolerance = 0.08),# dimension *and* approx. values (no NA)
+ 	  identical(variable.names(rm1), variable.names(cm1)),
+ 	  all.equal(residuals(rm1), residuals(cm1), tolerance = 0.05),# incl. names
+ 	  all.equal(rstudent (rm1), rstudent (cm1), tolerance = 0.06),
+ 	  identical(dimnames(rm1), dimnames(cm1)),
+ 	  all.equal(dummy.coef(rm1), dummy.coef(cm1), tolerance= .5)) ## check mostly structure
> 
> ## other helper functions
> stopifnot(identical(case.names(rm1), case.names(cm1)),
+           all.equal(family(rm1), family(cm1)),# identical() upto environment
+           identical(formula(rm1), formula(cm1)),
+           nobs(rm1) == nobs(cm1))
> #add1(rm0, ~ . + x3 + x4 + x5) ## does not return valid results (yet)!
> 
> 
> ## test other initial estimators
> lmrob(y ~ x1*x2 + x3 + x4 + x5, data, init="M-S")

Call:
lmrob(formula = y ~ x1 * x2 + x3 + x4 + x5, data = data, init = "M-S")
 \--> method = "M-SM"
Coefficients:
(Intercept)          x1b          x1c          x2B          x2C           x3  
    0.43584      0.59961      0.03464      0.20054      0.18774     -0.13954  
         x4           x5      x1b:x2B      x1c:x2B      x1b:x2C      x1c:x2C  
   -0.21848           NA     -1.89573           NA     -0.86976           NA  

Warning message:
In lmrob.M.S(x, y, control, mf) :
   Skipping design matrix equilibration (DGEEQU): row 12 is exactly zero.
> lmrob(y ~ x1*x2 + x3 + x4 + x5, data, init=lmrob.lar)

Call:
lmrob(formula = y ~ x1 * x2 + x3 + x4 + x5, data = data, init = lmrob.lar)
 \--> method = "lM"
Coefficients:
(Intercept)          x1b          x1c          x2B          x2C           x3  
  0.5611306    0.4443386    0.0001844    0.5303030   -0.2517937    0.2365411  
         x4           x5      x1b:x2B      x1c:x2B      x1b:x2C      x1c:x2C  
 -0.0826798           NA   -1.2984182           NA   -0.5976018           NA  

> 
> ## test all zero design matrix
> data <- data.frame(y=1:10,x1=0,x2=0,os=2,w=c(0.5, 1))
> (m5 <- lmrob(y ~ 1+x1+x2+offset(os), data, weights=w))

Call:
lmrob(formula = y ~ 1 + x1 + x2 + offset(os), data = data, weights = w)
 \--> method = "MM"
Coefficients:
(Intercept)           x1           x2  
      3.641           NA           NA  

> (sm5 <- summary(m5))

Call:
lmrob(formula = y ~ 1 + x1 + x2 + offset(os), data = data, weights = w)
 \--> method = "MM"
Residuals:
    Min      1Q  Median      3Q     Max 
-4.6412 -2.3912 -0.1412  2.1088  4.3588 

Coefficients: (2 not defined because of singularities)
            Estimate Std. Error t value Pr(>|t|)   
(Intercept)    3.641      1.030   3.534  0.00637 **
x1                NA         NA      NA       NA   
x2                NA         NA      NA       NA   
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Robust residual standard error: 3.244 
Convergence in 8 IRWLS iterations

Robustness weights: 
     1      2      3      4      5      6      7      8      9     10 
0.9089 0.8885 0.9700 0.9768 0.9982 0.9989 0.9920 0.9524 0.9518 0.8423 
Algorithmic parameters: 
       tuning.chi                bb        tuning.psi        refine.tol 
        1.548e+00         5.000e-01         4.685e+00         1.000e-07 
          rel.tol         solve.tol       eps.outlier             eps.x 
        1.000e-07         1.000e-07         1.000e-02         1.819e-12 
warn.limit.reject warn.limit.meanrw 
        5.000e-01         5.000e-01 
     nResample         max.it       best.r.s       k.fast.s          k.max 
           500             50              2              1            200 
   maxit.scale      trace.lev            mts     compute.rd fast.s.large.n 
           200              0           1000              0           2000 
                  psi           subsampling                   cov 
           "bisquare"         "nonsingular"         ".vcov.avar1" 
compute.outlier.stats 
                 "SM" 
seed : int(0) 
> (m6 <- lmrob(y ~ 0+x1+x2+offset(os), data, weights=w))

Call:
lmrob(formula = y ~ 0 + x1 + x2 + offset(os), data = data, weights = w)
 \--> method = "MM"
Coefficients:
x1  x2  
NA  NA  

> (sm6 <- summary(m6))

Call:
lmrob(formula = y ~ 0 + x1 + x2 + offset(os), data = data, weights = w)
 \--> method = "MM"
Weighted Residuals:
   Min     1Q Median     3Q    Max 
-3.828 -1.371  1.086  3.543  6.000 

Coefficients: (2 not defined because of singularities)
   Estimate Std. Error t value Pr(>|t|)
x1       NA         NA      NA       NA
x2       NA         NA      NA       NA

Robust residual standard error: NA 
Convergence in 0 IRWLS iterations

Robustness weights: 
 [1] NA NA NA NA NA NA NA NA NA NA
Algorithmic parameters: 
       tuning.psi           rel.tol         solve.tol       eps.outlier 
        4.6850610         0.0000001         0.0000001         0.0100000 
warn.limit.reject warn.limit.meanrw 
        0.5000000         0.5000000 
        max.it    maxit.scale      trace.lev     compute.rd fast.s.large.n 
            50            200              0              0           2000 
         eps.x 
             0 
                  psi                   cov compute.outlier.stats 
           "bisquare"         ".vcov.avar1"                  "SM" 
seed : int(0) 
> 
> sc5 <- summary(cm5 <- lm(y ~ 1+x1+x2+offset(os), data, weights=w))
> sc6 <- summary(cm6 <- lm(y ~ 0+x1+x2+offset(os), data, weights=w))
> 
> stopifnot(all.equal(coef(m5), coef(cm5), tolerance = 0.01),
+           identical(coef(m6), coef(cm6)),
+           all.equal(coef(sm5), coef(sc5), tolerance = 0.05),
+           identical(coef(sm6), coef(sc6)),
+           identical(sm5$df, sc5$df),
+           identical(sm6$df, sc6$df))
> 
> proc.time()
   user  system elapsed 
  0.637   0.096   0.724 
